# Geneology of Physical Philosophies of Mind

Some of the latest research in the philosophy of mind has to do with
determining what systems are conscious and what is the proper
definition of "intelligent behavior". Neurological indicators called the neural
correlates of consciousness (NCC) have been adopted as the "minimal set of
neural events and structures sufficient for a specific conscious experience."
We cognitive scientists have arrived at the search for brain structures and
activities that indicate conscious thinking is occurring by way of a series of
precursor philosophies of mind.

Theories and postulates of NCCs are descendants of monism, the belief that
there is but one basis for brain and mind. There is also the discredited, yet
important to consider, dualist perspective that we leave alone for now.
There are two important foundational monist theories:
idealism and physicalism. Idealism says that the entire universe is
mental, that is all that we see, feel, experience is but a fleeting illusion.
Such a statement cannot be falsified or proven, and is thus outside the realm
of science and utility. Physicalism, on the other hand, says that mind is
related, to some degree, by the same matter that makes up our bodies, chairs,
tables, the mountains, etc. Well before the discovery of the atom, the Greek
philosopher Democritus (ca. 460---370 BCE) asserted that all things were
composed of "atoms", mind included.

Physicalism may be further broken down into other "isms", shorthand now for
"philosophies of mind". These relevant philosophies of mind are
**identity theory**, **eliminativsm**, **functionalism**, and **emergence**,
which developed in that order. Identity theory says that for every "mental
state" there is one and only one "brain state" and vice-versa. Eliminativism
is so named because its innovation on identity theory is the elimination
of "mental states" altogether.

Functionalism starts with "functions" or behaviors, for example the production
of speech. The **multiple realization** argument against idealism claims that
there could well be a multitude of ways, either within an individual or
between individuals, that results in a particular function. One example given
in the book is that of being in a state of pain: different parts of the brain
may become active when, say, a squid is in pain versus when a human is in pain.
Do we ever feel pain the exact same way twice? Or see the color red? Or
recognize a word? It could easily seem unlikely that the exact same
physiological response happens every time one of these three things happens,
even if it's pain in the same region, the same exact hue, or the same exact
word.

Functionalism and identity theory are physicalist in that they both assume that
"mental states", while real enough, are not themselves composed of physical
things. John R. Searle, a famous cognitive scientist, argues that
consciousness, and thus "mental states", are an **emergent property** of
the brain. A simpler example of emergence from chemistry (given on p. 45 of
Friedenberg & Silverman) is that of water, H$_2$O. The chemical behavior of
hydrogen and oxygen on their own could not possibly be predicted. Both hydrogen
and oxygen gas are highly flammable and as we are all familiar water is not
at all flammable. So resistance to combustion is an emergent property of
water. With this understanding of emergence we can understand its opposite,
**reductionism**, which is the view that the functioning of any system can be
completely explained and predicted by the functioning of its individual parts.

We want to ask also what is intelligence and what is intelligent behavior?
Is it possible for non-biological entities to be intelligent? Artificial
intelligence has made truly impressive strides from autonomous animal robots
to the Watson computer system that beat former Jeopardy champions and
is now used "for utilization management decisions in lung cancer treatment at
Memorial Sloan Kettering Cancer Center" (Wikipedia article: https://en.wikipedia.org/wiki/Watson_(computer)). But is this intelligent in the way humans are intelligent?
In what ways are humans intelligent?

Can a machine ever become conscious or not? If it did, how could we know?
The Chinese Room thought experiment, or "Chinese room scenario" as
Friedenberg & Silverman say (p. 54), provides a situation where an "inanimate"
system shows "intelligence" but it cannot be said that the system truly
"understood" what was happening. In the Chinese room scenario, the system is
a person in a room where questions written in Chinese are passed in. There
is a person in the room with a book of pre-determined responses for any
potential question that came in. The person inside does not know any Chinese
and thus cannot truly understand the Chinese, but an outside observer
might conclude the opposite.

This argument is aimed at refuting the **Strong AI** claim that "consciousness
can arise from a purely physical process" (Friedenberg & Silverman p. 53).
The argument and responses to it are summarized at
([The Chinese Room Argument, Stanford Encyclopedia of Philosophy](
http://plato.stanford.edu/archives/win2015/entries/chinese-room/)). There is
also a **weak AI** argument "that consciousness is itself either not a physical
process, and so can never be reproduced, or a physical process but such a
complex one that we will never be able to duplicate it artificially"
(F&S p. 54).

One intuitively satisfying objection to the Chinese Room Argument is the
so-called ["Systems Reply (Stanford Encyclopedia of Philosophy)"](
http://plato.stanford.edu/archives/win2015/entries/chinese-room/#4.1), which
makes the simple observation that, taken as a whole, there is consciousness
in the system, namely in the person sitting esconsed within the room.
Furthermore, the system, when considered as a whole, does understand Chinese.


# Experimental Philosophy: The Knobe Effect

Traditionally, as F&P claim on p. 56, "philosophy is a nonempirical approach"
meaning "it does not utilize the scientific method". But surely philosophy of
the mind depends on results borne of the scientific method. There is a
burgeoning branch of philosophy of mind called "Experimental Philosophy" that
doesn't wait around for someone else to do experiments based on their theroies.
Instead they perform simple experiments to begin to build an experimental
foundation for their findings. In some sense these should simply be thought of
as prototypes for others to follow in building a larger body of more
sophisticated results. Some critics, though, argue that in doing
scientifically valid experiments that the "X-Philers" as they're called are no
longer philosophers but psychologists.

A well-known experimental philosophy paper is by Joshua Knobe, where he
poses one of the following questions to participants from two different groups,
one for each version of the question:

1. The vice-president of a company went to the chairman of the board and said,
"We are thinking of starting a new program. It will help us increase profits,
but it will also harm the environment."
The chairman of the board answered, "I don’t care at all about harming the
environment. I just want to make as much profit as I can. Let’s start the new program."
They started the new program. Sure enough, the environment was harmed.
These

2. The vice-president of a company went to the chairman of the board and said,
"We are thinking of starting a new program. It will help us increase profits,
and it will also help the environment."
The chairman of the board answered, "I don’t care at all about helping the environment. I just want to make as much profit as I can. Let’s start the new program."
They started the new program. Sure enough, the environment was helped.

Amazingly, when the group reading 1) was asked "did the chairman intentionally
harm the environment?" 82% said yes. However, when the other group reading 2)
was asked "did the chairman intentionally help the environment?" nearly as
many, 77%, said no, the chairman did not intenionally help the environment.

The paper provides another example, instead with the decision of a lieutenant
to either put some troops into or take them out of the line of fire. The first
scenario:

1. A lieutenant was talking with a sergeant. The lieutenant gave the order: ‘Send your squad to the top of Thompson Hill.’
The sergeant said: ‘But if I send my squad to the top of Thompson Hill, we’ll be moving the men directly into the enemy’s line of fire. Some of them will surely be killed!’
The lieutenant answered: ‘Look, I know that they’ll be in the line of fire, and I know that some of them will be killed. But I don’t care at all about what happens to our soldiers. All I care about is taking control of Thompson Hill.’
The squad was sent to the top of Thompson Hill. As expected, the soldiers were moved into the enemy’s line of fire, and some of them were killed.

The second:

2. A lieutenant was talking with a sergeant. The lieutenant gave the order: ‘Send your squad to the top of Thompson Hill.’
intentional action and side effects in ordinary language 193
The sergeant said: ‘If I send my squad to the top of Thompson Hill, we’ll be taking the men out of the enemy’s line of fire. They’ll be rescued!’
The lieutenant answered: ‘Look, I know that we’ll be taking them out of the line of fire, and I know that some of them would have been killed otherwise. But I don’t care at all about what happens to our soldiers. All I care about is taking control of Thompson Hill.’
The squad was sent to the top of Thompson Hill. As expected, the soldiers were taken out of the enemy’s line of fire, and they thereby escaped getting killed.

Now the subjects were asked whether or not the lieutenant put the soldiers in
or took the soldiers out of the line of fire. Similar to the first results,
in the "harm" scenario, scenario 1),
77% of subjects said the lieutenant intentionaly put his soldiers into the line
of fire, whereas 70% of the subjects reading scenario 2) said the lieutenant did
not intentionally remove the soldiers from the enemy line of fire.

We will consider the final paragraph in [Knobe 2003](
http://www.blackwell-synergy.com/links/doi/10.1111%2F1467-8284.00419), which
says

> there seems to be an asymmetry whereby people are considerably more willing to blame the agent for bad side effects than to praise the agent for good side effects. And this asymmetry in people’s assignment of praise and blame may be at the root of the corresponding asymmetry in people’s application of the concept intentional: namely, that they seem considerably more willing to say that a side effect was brought about intentionally when they regard that side effect as bad than when they regard it as good.

Does this mean that our moral reasoning is polluted by how a thing is phrased?
What, if anything, can we determine about the basic meaning of "intention" or
what moral behavior is?
